{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588d6f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T09:00:29.686925Z",
     "iopub.status.busy": "2025-11-09T09:00:29.686588Z",
     "iopub.status.idle": "2025-11-09T09:05:03.228186Z",
     "shell.execute_reply": "2025-11-09T09:05:03.226854Z"
    },
    "papermill": {
     "duration": 273.546483,
     "end_time": "2025-11-09T09:05:03.229495",
     "exception": true,
     "start_time": "2025-11-09T09:00:29.683012",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0.0\r\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting matplotlib\r\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting pandas\r\n",
      "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.226-py3-none-any.whl.metadata (37 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\r\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib)\r\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\r\n",
      "  Downloading fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m156.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\r\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\r\n",
      "Collecting packaging>=20.0 (from matplotlib)\r\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting pillow>=8 (from matplotlib)\r\n",
      "  Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\r\n",
      "Collecting pyparsing>=3 (from matplotlib)\r\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\r\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas)\r\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas)\r\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\r\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\r\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\r\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\r\n",
      "Collecting requests>=2.23.0 (from ultralytics)\r\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting scipy>=1.4.1 (from ultralytics)\r\n",
      "  Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m252.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch>=1.8.0 (from ultralytics)\r\n",
      "  Downloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\r\n",
      "Collecting torchvision>=0.9.0 (from ultralytics)\r\n",
      "  Downloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\r\n",
      "Collecting psutil (from ultralytics)\r\n",
      "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\r\n",
      "Collecting polars (from ultralytics)\r\n",
      "  Downloading polars-1.35.1-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\r\n",
      "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\r\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib)\r\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\r\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\r\n",
      "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\r\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\r\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\r\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting filelock (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting typing-extensions>=4.10.0 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting sympy>=1.13.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx>=2.5.1 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting jinja2 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting fsspec>=0.8.5 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\r\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==3.5.0 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting polars-runtime-32==1.35.1 (from polars->ultralytics)\r\n",
      "  Downloading polars_runtime_32-1.35.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.8.0->ultralytics)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.8.0->ultralytics)\r\n",
      "  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\r\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m277.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m293.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m287.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics-8.3.226-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m361.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 kB\u001b[0m \u001b[31m330.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m304.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m340.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m284.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m258.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m242.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m300.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m320.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m346.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m258.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m286.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m309.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m313.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m283.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m276.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m263.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m349.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m322.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m255.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m365.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m259.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m263.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m244.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m326.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m213.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m204.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m304.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m306.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m265.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m279.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m350.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\r\n",
      "Downloading polars-1.35.1-py3-none-any.whl (783 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m783.6/783.6 kB\u001b[0m \u001b[31m322.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading polars_runtime_32-1.35.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m263.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m340.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2025.10.5-py3-none-any.whl (163 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m350.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m335.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m342.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m241.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m341.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m279.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m271.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m313.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m329.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\r\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m351.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pytz, nvidia-cusparselt-cu12, mpmath, urllib3, tzdata, typing-extensions, triton, sympy, six, pyyaml, pyparsing, psutil, polars-runtime-32, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, idna, fsspec, fonttools, filelock, cycler, charset_normalizer, certifi, scipy, requests, python-dateutil, polars, opencv-python, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, contourpy, pandas, nvidia-cusolver-cu12, matplotlib, torch, ultralytics-thop, torchvision, ultralytics\r\n",
      "  Attempting uninstall: pytz\r\n",
      "    Found existing installation: pytz 2025.2\r\n",
      "    Uninstalling pytz-2025.2:\r\n",
      "      Successfully uninstalled pytz-2025.2\r\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\r\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\r\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\r\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\r\n",
      "  Attempting uninstall: mpmath\r\n",
      "    Found existing installation: mpmath 1.3.0\r\n",
      "    Uninstalling mpmath-1.3.0:\r\n",
      "      Successfully uninstalled mpmath-1.3.0\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 2.5.0\r\n",
      "    Uninstalling urllib3-2.5.0:\r\n",
      "      Successfully uninstalled urllib3-2.5.0\r\n",
      "  Attempting uninstall: tzdata\r\n",
      "    Found existing installation: tzdata 2025.2\r\n",
      "    Uninstalling tzdata-2025.2:\r\n",
      "      Successfully uninstalled tzdata-2025.2\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.15.0\r\n",
      "    Uninstalling typing_extensions-4.15.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.15.0\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.13.1\r\n",
      "    Uninstalling sympy-1.13.1:\r\n",
      "      Successfully uninstalled sympy-1.13.1\r\n",
      "  Attempting uninstall: six\r\n",
      "    Found existing installation: six 1.17.0\r\n",
      "    Uninstalling six-1.17.0:\r\n",
      "      Successfully uninstalled six-1.17.0\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0.3\r\n",
      "    Uninstalling PyYAML-6.0.3:\r\n",
      "      Successfully uninstalled PyYAML-6.0.3\r\n",
      "  Attempting uninstall: pyparsing\r\n",
      "    Found existing installation: pyparsing 3.0.9\r\n",
      "    Uninstalling pyparsing-3.0.9:\r\n",
      "      Successfully uninstalled pyparsing-3.0.9\r\n",
      "  Attempting uninstall: psutil\r\n",
      "    Found existing installation: psutil 7.1.0\r\n",
      "    Uninstalling psutil-7.1.0:\r\n",
      "      Successfully uninstalled psutil-7.1.0\r\n",
      "  Attempting uninstall: pillow\r\n",
      "    Found existing installation: pillow 11.3.0\r\n",
      "    Uninstalling pillow-11.3.0:\r\n",
      "      Successfully uninstalled pillow-11.3.0\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 25.0\r\n",
      "    Uninstalling packaging-25.0:\r\n",
      "      Successfully uninstalled packaging-25.0\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "  Attempting uninstall: networkx\r\n",
      "    Found existing installation: networkx 3.5\r\n",
      "    Uninstalling networkx-3.5:\r\n",
      "      Successfully uninstalled networkx-3.5\r\n",
      "  Attempting uninstall: MarkupSafe\r\n",
      "    Found existing installation: MarkupSafe 3.0.2\r\n",
      "    Uninstalling MarkupSafe-3.0.2:\r\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\r\n",
      "  Attempting uninstall: kiwisolver\r\n",
      "    Found existing installation: kiwisolver 1.4.8\r\n",
      "    Uninstalling kiwisolver-1.4.8:\r\n",
      "      Successfully uninstalled kiwisolver-1.4.8\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.10\r\n",
      "    Uninstalling idna-3.10:\r\n",
      "      Successfully uninstalled idna-3.10\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.9.0\r\n",
      "    Uninstalling fsspec-2025.9.0:\r\n",
      "      Successfully uninstalled fsspec-2025.9.0\r\n",
      "  Attempting uninstall: fonttools\r\n",
      "    Found existing installation: fonttools 4.59.0\r\n",
      "    Uninstalling fonttools-4.59.0:\r\n",
      "      Successfully uninstalled fonttools-4.59.0\r\n",
      "  Attempting uninstall: filelock\r\n",
      "    Found existing installation: filelock 3.19.1\r\n",
      "    Uninstalling filelock-3.19.1:\r\n",
      "      Successfully uninstalled filelock-3.19.1\r\n",
      "  Attempting uninstall: cycler\r\n",
      "    Found existing installation: cycler 0.12.1\r\n",
      "    Uninstalling cycler-0.12.1:\r\n",
      "      Successfully uninstalled cycler-0.12.1\r\n",
      "  Attempting uninstall: charset_normalizer\r\n",
      "    Found existing installation: charset-normalizer 3.4.3\r\n",
      "    Uninstalling charset-normalizer-3.4.3:\r\n",
      "      Successfully uninstalled charset-normalizer-3.4.3\r\n",
      "  Attempting uninstall: certifi\r\n",
      "    Found existing installation: certifi 2025.8.3\r\n",
      "    Uninstalling certifi-2025.8.3:\r\n",
      "      Successfully uninstalled certifi-2025.8.3\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.15.3\r\n",
      "    Uninstalling scipy-1.15.3:\r\n",
      "      Successfully uninstalled scipy-1.15.3\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.32.5\r\n",
      "    Uninstalling requests-2.32.5:\r\n",
      "      Successfully uninstalled requests-2.32.5\r\n",
      "  Attempting uninstall: python-dateutil\r\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\r\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\r\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\r\n",
      "  Attempting uninstall: polars\r\n",
      "    Found existing installation: polars 1.25.0\r\n",
      "    Uninstalling polars-1.25.0:\r\n",
      "      Successfully uninstalled polars-1.25.0\r\n",
      "  Attempting uninstall: opencv-python\r\n",
      "    Found existing installation: opencv-python 4.12.0.88\r\n",
      "    Uninstalling opencv-python-4.12.0.88:\r\n",
      "      Successfully uninstalled opencv-python-4.12.0.88\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: jinja2\r\n",
      "    Found existing installation: Jinja2 3.1.6\r\n",
      "    Uninstalling Jinja2-3.1.6:\r\n",
      "      Successfully uninstalled Jinja2-3.1.6\r\n",
      "  Attempting uninstall: contourpy\r\n",
      "    Found existing installation: contourpy 1.3.2\r\n",
      "    Uninstalling contourpy-1.3.2:\r\n",
      "      Successfully uninstalled contourpy-1.3.2\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.3\r\n",
      "    Uninstalling pandas-2.2.3:\r\n",
      "      Successfully uninstalled pandas-2.2.3\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: matplotlib\r\n",
      "    Found existing installation: matplotlib 3.7.2\r\n",
      "    Uninstalling matplotlib-3.7.2:\r\n",
      "      Successfully uninstalled matplotlib-3.7.2\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\r\n",
      "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\r\n",
      "datasets 4.1.1 requires fsspec[http]<=2025.9.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.7 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.3 which is incompatible.\r\n",
      "google-cloud-bigtable 2.32.0 requires google-api-core[grpc]<3.0.0,>=2.17.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "tokenizers 0.21.2 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.9.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires polars<1.29,>=1.25, but you have polars 1.35.1 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 certifi-2025.10.5 charset_normalizer-3.4.4 contourpy-1.3.3 cycler-0.12.1 filelock-3.20.0 fonttools-4.60.1 fsspec-2025.10.0 idna-3.11 jinja2-3.1.6 kiwisolver-1.4.9 matplotlib-3.10.7 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 opencv-python-4.11.0.86 packaging-25.0 pandas-2.3.3 pillow-12.0.0 polars-1.35.1 polars-runtime-32-1.35.1 psutil-7.1.3 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 scipy-1.16.3 six-1.17.0 sympy-1.14.0 torch-2.9.0 torchvision-0.24.0 triton-3.5.0 typing-extensions-4.15.0 tzdata-2025.2 ultralytics-8.3.226 ultralytics-thop-2.0.18 urllib3-2.5.0\r\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_Ink' from 'PIL._typing' (/usr/local/lib/python3.11/dist-packages/PIL/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/1138180418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install numpy==1.26.4 --no-cache-dir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m\"\"\"Lazy-import model classes on first access.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODELS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ultralytics.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfastsam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNAS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrtdetr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRTDETR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/fastsam/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAMPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAMValidator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/fastsam/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAMPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTASK2DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_save_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mguess_model_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaml_model_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m from ultralytics.utils import (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/results.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLetterBox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOGGER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataExportMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_one_box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_grounding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_inference_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from .dataset import (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFORMATS_HELP_MSG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHELP_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_FORMATS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_file_speeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEFAULT_CFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOGGER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_THREADS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTQDM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautobackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_class_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m from ultralytics.utils import (\n\u001b[1;32m     22\u001b[0m     \u001b[0mASSETS_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from .tasks import (\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mClassificationModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_divisible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m from ultralytics.utils.torch_utils import (\n\u001b[1;32m     86\u001b[0m     \u001b[0mfuse_conv_and_bn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/plotting.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpil_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageDraw.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageText.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_Ink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_Ink' from 'PIL._typing' (/usr/local/lib/python3.11/dist-packages/PIL/_typing.py)"
     ]
    }
   ],
   "source": [
    "# Step 1: Reinstall core scientific stack with compatible versions\n",
    "!pip install --no-cache-dir \"numpy<2.0.0\" \"matplotlib\" \"pandas\" \"ultralytics\" --force-reinstall\n",
    "\n",
    "# # Step 2: Restart the kernel (mandatory!)\n",
    "import os\n",
    "# os._exit(00)\n",
    "\n",
    "# Step 3: Now import everything (after restart)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "!pip install numpy==1.26.4 --no-cache-dir\n",
    "!pip install matplotlib==3.8.4 --no-cache-dir\n",
    "!pip install ultralytics==8.2.75 --no-cache-dir\n",
    "!pip install pandas==2.2.2 --no-cache-dir\n",
    "!pip install seaborn==0.13.2 --no-cache-dir\n",
    "!pip install opencv-python==4.9.0.80 --no-cache-dir\n",
    "!pip install torch>=2.0.0 --no-cache-dir\n",
    "\n",
    "import numpy as np\n",
    "print(np.__version__)  # Should be < 2.0.0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([1,2,3])\n",
    "plt.show()\n",
    "\n",
    "# Run this once\n",
    "!pip install --no-cache-dir \"numpy<2.0.0\" \"matplotlib\" \"ultralytics\" --force-reinstall\n",
    "\n",
    "# Then restart kernel\n",
    "# import os; os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6cac82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T07:41:44.160389Z",
     "iopub.status.busy": "2025-11-09T07:41:44.159853Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Road Damage Detection Training Script (Kaggle-Optimized)\n",
    "Fixed: wandb, NumPy, paths, FileNotFoundError, auto-create folders\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Machine Learning\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, accuracy_score,\n",
    "    roc_curve, auc, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# YOLOv8\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "\n",
    "class RoadDamageTrainer:\n",
    "    def __init__(self, dataset_root, output_dir, epochs=100, batch_size=16, img_size=640, max_images_per_dataset=None):\n",
    "        self.dataset_root = dataset_root\n",
    "        self.output_dir = output_dir\n",
    "        self.epochs = max(epochs, 100)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.max_images_per_dataset = max_images_per_dataset\n",
    "        \n",
    "        self.VALID_CLASSES = ['D00', 'D10', 'D20', 'D40', 'D43', 'D44']\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.VALID_CLASSES)}\n",
    "        self.num_classes = len(self.VALID_CLASSES)\n",
    "        \n",
    "        self.dataset_paths = {\n",
    "            'India': {\n",
    "                'train_images': '/kaggle/input/dut-rdd/RDD2022_India/India/test/images',\n",
    "                'train_annotations': '/kaggle/input/dut-rdd/RDD2022_India/India/test/annotations',\n",
    "            },\n",
    "            'Czech': {\n",
    "                'train_images': '/kaggle/input/rdd2022-more/RDD2022_Czech/Czech/train/images',\n",
    "                'train_annotations': '/kaggle/input/dut-rdd/RDD2022_Czech/train/annotations',\n",
    "            },\n",
    "            'China_MotorBike': {\n",
    "                'train_images': '/kaggle/input/dut-rdd/RDD2022_China_MotorBike/China_MotorBike/train/images',\n",
    "                'train_annotations': '/kaggle/input/dut-rdd/RDD2022_China_MotorBike/China_MotorBike/train/annotations',\n",
    "            },\n",
    "            'China_Drone': {\n",
    "                'train_images': '/kaggle/input/dut-rdd/RDD2022_China_Drone/China_Drone/train/images',\n",
    "                'train_annotations': '/kaggle/input/dut-rdd/RDD2022_China_Drone/China_Drone/train/annotations',\n",
    "            },\n",
    "            'Japan': {\n",
    "                'train_images': '/kaggle/input/rdd2022-more/RDD2022_Japan/Japan/train/images',\n",
    "                'train_annotations': '/kaggle/input/rdd2022-more/RDD2022_Japan/Japan/train/annotations',\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        self.setup_directories()\n",
    "        \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        print(f\"Training for {self.epochs} epochs\")\n",
    "        if self.max_images_per_dataset:\n",
    "            print(f\"Limited mode: Max {self.max_images_per_dataset} images per dataset\")\n",
    "        else:\n",
    "            print(f\"Loading all available images\")\n",
    "\n",
    "    def setup_directories(self):\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(os.path.join(self.output_dir, f'{split}/images'), exist_ok=True)\n",
    "            os.makedirs(os.path.join(self.output_dir, f'{split}/labels'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.output_dir, 'metrics'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.output_dir, 'visualizations'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.output_dir, 'models'), exist_ok=True)\n",
    "        print(f\"Output directories ready: {self.output_dir}\")\n",
    "\n",
    "    def parse_xml_to_yolo(self, xml_path, img_width, img_height):\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        boxes, labels = [], []\n",
    "        for obj in root.findall('object'):\n",
    "            cls_name = obj.find('name').text\n",
    "            if cls_name not in self.VALID_CLASSES:\n",
    "                continue\n",
    "            cls_idx = self.class_to_idx[cls_name]\n",
    "            bbox = obj.find('bndbox')\n",
    "            xmin = float(bbox.find('xmin').text)\n",
    "            ymin = float(bbox.find('ymin').text)\n",
    "            xmax = float(bbox.find('xmax').text)\n",
    "            ymax = float(bbox.find('ymax').text)\n",
    "            if xmax <= xmin or ymax <= ymin:\n",
    "                continue\n",
    "            center_x = (xmin + xmax) / 2 / img_width\n",
    "            center_y = (ymin + ymax) / 2 / img_height\n",
    "            width = (xmax - xmin) / img_width\n",
    "            height = (ymax - ymin) / img_height\n",
    "            boxes.append([center_x, center_y, width, height])\n",
    "            labels.append(cls_idx)\n",
    "        return boxes, labels\n",
    "\n",
    "    def load_dataset(self):\n",
    "        print(\"\\nLoading dataset...\")\n",
    "        all_images, all_labels, dataset_stats = [], [], {}\n",
    "        \n",
    "        for name, paths in self.dataset_paths.items():\n",
    "            img_dir = paths['train_images']\n",
    "            ann_dir = paths['train_annotations']\n",
    "            if not os.path.exists(img_dir) or not os.path.exists(ann_dir):\n",
    "                print(f\"Skipping {name}: Not found\")\n",
    "                continue\n",
    "            \n",
    "            count = 0\n",
    "            img_files = os.listdir(img_dir)\n",
    "            if self.max_images_per_dataset:\n",
    "                img_files = img_files[:self.max_images_per_dataset]\n",
    "            \n",
    "            for img_file in tqdm(img_files, desc=f\"Loading {name}\"):\n",
    "                if self.max_images_per_dataset and count >= self.max_images_per_dataset:\n",
    "                    break\n",
    "                if not img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    continue\n",
    "                \n",
    "                img_path = os.path.join(img_dir, img_file)\n",
    "                xml_path = os.path.join(ann_dir, 'xmls', Path(img_file).stem + '.xml')\n",
    "                if not os.path.exists(xml_path):\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                h, w = img.shape[:2]\n",
    "                \n",
    "                try:\n",
    "                    boxes, labels = self.parse_xml_to_yolo(xml_path, w, h)\n",
    "                    if boxes:\n",
    "                        all_images.append(img_path)\n",
    "                        all_labels.append((boxes, labels, xml_path))\n",
    "                        count += 1\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            dataset_stats[name] = count\n",
    "            print(f\"  {name}: {count} images\")\n",
    "        \n",
    "        print(f\"\\nTotal valid pairs: {len(all_images)}\")\n",
    "        with open(os.path.join(self.output_dir, 'metrics', 'dataset_stats.json'), 'w') as f:\n",
    "            json.dump(dataset_stats, f, indent=2)\n",
    "        \n",
    "        return all_images, all_labels\n",
    "\n",
    "    def preprocess_and_save(self, images, labels, split='train'):\n",
    "        img_out = os.path.join(self.output_dir, f'{split}/images')\n",
    "        lbl_out = os.path.join(self.output_dir, f'{split}/labels')\n",
    "        for img_path, (boxes, lbls, _) in tqdm(zip(images, labels), desc=f\"Processing {split}\", total=len(images)):\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "            name = os.path.basename(img_path)\n",
    "            cv2.imwrite(os.path.join(img_out, name), img)\n",
    "            with open(os.path.join(lbl_out, Path(name).stem + '.txt'), 'w') as f:\n",
    "                for box, lbl in zip(boxes, lbls):\n",
    "                    f.write(f\"{lbl} {' '.join(map(str, box))}\\n\")\n",
    "\n",
    "    def split_dataset(self, images, labels):\n",
    "        print(\"\\nSplitting dataset...\")\n",
    "        train_imgs, test_imgs, train_lbls, test_lbls = train_test_split(images, labels, test_size=0.1, random_state=42)\n",
    "        train_imgs, val_imgs, train_lbls, val_lbls = train_test_split(train_imgs, train_lbls, test_size=0.1111, random_state=42)\n",
    "        self.preprocess_and_save(train_imgs, train_lbls, 'train')\n",
    "        self.preprocess_and_save(val_imgs, val_lbls, 'val')\n",
    "        self.preprocess_and_save(test_imgs, test_lbls, 'test')\n",
    "        print(f\"  Train: {len(train_imgs)} | Val: {len(val_imgs)} | Test: {len(test_imgs)}\")\n",
    "        return len(train_imgs), len(val_imgs), len(test_imgs)\n",
    "\n",
    "    def create_yolo_config(self):\n",
    "        config = f\"\"\"path: {self.output_dir}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: {self.num_classes}\n",
    "names: {self.VALID_CLASSES}\n",
    "\"\"\"\n",
    "        path = os.path.join(self.output_dir, 'data.yaml')\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(config)\n",
    "        print(f\"YOLO config: {path}\")\n",
    "\n",
    "    def train(self, model_name='yolov8s.pt'):\n",
    "        print(f\"\\nStarting training with {model_name}...\")\n",
    "        os.environ['WANDB_DISABLED'] = 'true'  # Tắt wandb\n",
    "        \n",
    "        model = YOLO(model_name)\n",
    "        start = time.time()\n",
    "        \n",
    "        results = model.train(\n",
    "            data=os.path.join(self.output_dir, 'data.yaml'),\n",
    "            epochs=self.epochs,\n",
    "            imgsz=self.img_size,\n",
    "            batch=self.batch_size,\n",
    "            device=self.device,\n",
    "            augment=True,\n",
    "            lr0=0.001,\n",
    "            cos_lr=True,\n",
    "            patience=20,\n",
    "            amp=True,\n",
    "            save=True,\n",
    "            save_period=10,\n",
    "            project=self.output_dir,   # Lưu vào output_dir/train/\n",
    "            name='train',\n",
    "            exist_ok=True,\n",
    "            verbose=True,\n",
    "            plots=True\n",
    "        )\n",
    "        \n",
    "        training_time = time.time() - start\n",
    "        print(f\"Training completed in {training_time/60:.1f} min\")\n",
    "        \n",
    "        with open(os.path.join(self.output_dir, 'metrics', 'training_time.txt'), 'w') as f:\n",
    "            f.write(f\"{training_time:.2f}\\n\")\n",
    "        \n",
    "        return model, results, training_time\n",
    "\n",
    "    def extract_features(self, model, images, max_samples=2000):\n",
    "        print(\"\\nExtracting features for t-SNE...\")\n",
    "        features, labels = [], []\n",
    "        samples = random.sample(images, min(len(images), max_samples))\n",
    "        model.eval()\n",
    "        for path in tqdm(samples, desc=\"Extracting\"):\n",
    "            try:\n",
    "                img = cv2.resize(cv2.imread(path), (self.img_size, self.img_size))\n",
    "                lbl_path = path.replace('/images/', '/labels/').rsplit('.', 1)[0] + '.txt'\n",
    "                lbl = -1\n",
    "                if os.path.exists(lbl_path):\n",
    "                    with open(lbl_path) as f:\n",
    "                        line = f.readline().strip()\n",
    "                        if line:\n",
    "                            lbl = int(line.split()[0])\n",
    "                labels.append(lbl)\n",
    "                \n",
    "                res = model.predict(img, verbose=False)\n",
    "                if res and len(res[0].boxes) > 0:\n",
    "                    feats = [box.xywh[0].cpu().numpy() for box in res[0].boxes]\n",
    "                    features.append(np.mean(feats, axis=0))\n",
    "                else:\n",
    "                    features.append(np.zeros(4))\n",
    "            except:\n",
    "                continue\n",
    "        return np.array(features), np.array(labels)\n",
    "\n",
    "    def visualize_tsne(self, model, split='test'):\n",
    "        print(f\"\\nt-SNE for {split}...\")\n",
    "        img_dir = os.path.join(self.output_dir, f'{split}/images')\n",
    "        images = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        if not images:\n",
    "            print(\"No images for t-SNE\")\n",
    "            return\n",
    "        feats, lbls = self.extract_features(model, images)\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(feats)-1), n_iter=1000)\n",
    "        emb = tsne.fit_transform(feats)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, self.num_classes + 1))\n",
    "        for i in range(self.num_classes):\n",
    "            mask = lbls == i\n",
    "            plt.scatter(emb[mask, 0], emb[mask, 1], c=[colors[i]], label=self.VALID_CLASSES[i], alpha=0.6, s=50)\n",
    "        if np.any(lbls == -1):\n",
    "            plt.scatter(emb[lbls == -1, 0], emb[lbls == -1, 1], c='gray', label='No Detection', alpha=0.3, s=30, marker='x')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.title(f't-SNE ({split.upper()})')\n",
    "        plt.tight_layout()\n",
    "        path = os.path.join(self.output_dir, 'visualizations', f'tsne_{split}.png')\n",
    "        plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  Saved: {path}\")\n",
    "\n",
    "    def evaluate_model(self, model, split='test'):\n",
    "        print(f\"\\nEvaluating {split}...\")\n",
    "        img_dir = os.path.join(self.output_dir, f'{split}/images')\n",
    "        images = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        y_true, y_pred, y_scores = [], [], []\n",
    "        \n",
    "        for path in tqdm(images, desc=\"Predicting\"):\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            res = model.predict(img, conf=0.25, verbose=False)\n",
    "            \n",
    "            lbl_path = path.replace('/images/', '/labels/').rsplit('.', 1)[0] + '.txt'\n",
    "            if os.path.exists(lbl_path):\n",
    "                with open(lbl_path) as f:\n",
    "                    for line in f:\n",
    "                        y_true.append(int(line.split()[0]))\n",
    "            \n",
    "            if res and len(res[0].boxes) > 0:\n",
    "                for box in res[0].boxes:\n",
    "                    y_pred.append(int(box.cls))\n",
    "                    y_scores.append(float(box.conf))\n",
    "        \n",
    "        if not y_true or not y_pred:\n",
    "            print(\"No valid predictions!\")\n",
    "            return {}\n",
    "        \n",
    "        min_len = min(len(y_true), len(y_pred))\n",
    "        y_true, y_pred, y_scores = y_true[:min_len], y_pred[:min_len], y_scores[:min_len]\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        print(f\"\\nMetrics: Acc: {acc*100:.2f}% | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")\n",
    "        metrics = {'accuracy': float(acc), 'precision': float(prec), 'recall': float(rec), 'f1_score': float(f1)}\n",
    "        with open(os.path.join(self.output_dir, 'metrics', f'metrics_{split}.json'), 'w') as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        \n",
    "        report = classification_report(y_true, y_pred, target_names=self.VALID_CLASSES, zero_division=0)\n",
    "        print(f\"\\nClassification Report:\\n{report}\")\n",
    "        with open(os.path.join(self.output_dir, 'metrics', f'report_{split}.txt'), 'w') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        self.plot_confusion_matrix(y_true, y_pred, split)\n",
    "        self.plot_roc_curves(y_true, y_scores, split)\n",
    "        return metrics\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred, split):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.VALID_CLASSES, yticklabels=self.VALID_CLASSES)\n",
    "        plt.title(f'Confusion Matrix ({split.upper()})')\n",
    "        plt.ylabel('True')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.tight_layout()\n",
    "        path = os.path.join(self.output_dir, 'visualizations', f'cm_{split}.png')\n",
    "        plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  CM saved: {path}\")\n",
    "\n",
    "    def plot_roc_curves(self, y_true, y_scores, split):\n",
    "        y_true_bin = [1 if y >= 0 else 0 for y in y_true]\n",
    "        y_scores = np.array(y_scores)\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
    "        plt.plot([0,1],[0,1], 'k--')\n",
    "        plt.xlabel('FPR')\n",
    "        plt.ylabel('TPR')\n",
    "        plt.title(f'ROC ({split.upper()})')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        path = os.path.join(self.output_dir, 'visualizations', f'roc_{split}.png')\n",
    "        plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  ROC saved: {path} (AUC: {roc_auc:.4f})\")\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        print(\"\\nPlotting training history...\")\n",
    "        csv_path = os.path.join(self.output_dir, 'train', 'results.csv')\n",
    "        if not os.path.exists(csv_path):\n",
    "            print(\"No results.csv found\")\n",
    "            return\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        fig.suptitle('Training History', fontsize=16, fontweight='bold')\n",
    "        plots = [\n",
    "            ('train/box_loss', 'Box Loss'), ('train/cls_loss', 'Class Loss'), ('metrics/mAP50(B)', 'mAP@0.5'),\n",
    "            ('metrics/precision(B)', 'Precision'), ('metrics/recall(B)', 'Recall'), ('lr/pg0', 'LR')\n",
    "        ]\n",
    "        for ax, (col, title) in zip(axes.flat, plots):\n",
    "            if col in df.columns:\n",
    "                ax.plot(df['epoch'], df[col])\n",
    "                ax.set_title(title)\n",
    "                ax.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        path = os.path.join(self.output_dir, 'visualizations', 'history.png')\n",
    "        plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  History saved: {path}\")\n",
    "\n",
    "    def visualize_predictions(self, model, split='test', n_samples=10):\n",
    "        print(f\"\\nVisualizing {split} predictions...\")\n",
    "        img_dir = os.path.join(self.output_dir, f'{split}/images')\n",
    "        images = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        samples = random.sample(images, min(n_samples, len(images)))\n",
    "        \n",
    "        cols = 5\n",
    "        rows = (len(samples) + cols - 1) // cols\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(20, 4*rows))\n",
    "        axes = axes.flatten() if rows > 1 else [axes] if cols == 1 else axes\n",
    "        \n",
    "        for idx, path in enumerate(samples):\n",
    "            img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "            res = model.predict(img, conf=0.25, verbose=False)\n",
    "            if res and len(res[0].boxes) > 0:\n",
    "                for box in res[0].boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls)\n",
    "                    conf = float(box.conf)\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(img, f\"{self.VALID_CLASSES[cls]} {conf:.2f}\", (x1, y1-10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis('off')\n",
    "            axes[idx].set_title(os.path.basename(path), fontsize=8)\n",
    "        for idx in range(len(samples), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        plt.tight_layout()\n",
    "        path = os.path.join(self.output_dir, 'visualizations', f'pred_{split}.png')\n",
    "        plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"  Predictions saved: {path}\")\n",
    "\n",
    "    def run(self):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ROAD DAMAGE DETECTION PIPELINE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        images, labels = self.load_dataset()\n",
    "        if len(images) == 0:\n",
    "            print(\"ERROR: Không có ảnh nào được tải. Kiểm tra dataset.\")\n",
    "            return\n",
    "        \n",
    "        self.split_dataset(images, labels)\n",
    "        self.create_yolo_config()\n",
    "        model, _, training_time = self.train('yolov8s.pt')\n",
    "        \n",
    "        # TỰ ĐỘNG TẠO THƯ MỤC + SAO CHÉP MODEL\n",
    "        weights_dir = os.path.join(self.output_dir, 'train', 'weights')\n",
    "        best_pt = os.path.join(weights_dir, 'best.pt')\n",
    "        last_pt = os.path.join(weights_dir, 'last.pt')\n",
    "        final_model = os.path.join(self.output_dir, 'models', 'best_model.pt')\n",
    "        \n",
    "        os.makedirs(weights_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(final_model), exist_ok=True)\n",
    "        \n",
    "        if os.path.exists(best_pt):\n",
    "            shutil.copy(best_pt, final_model)\n",
    "            print(f\"Best model copied: {final_model}\")\n",
    "        elif os.path.exists(last_pt):\n",
    "            shutil.copy(last_pt, final_model)\n",
    "            print(f\"Using last.pt: {final_model}\")\n",
    "        else:\n",
    "            try:\n",
    "                model.save(final_model)\n",
    "                print(f\"Model saved manually: {final_model}\")\n",
    "            except:\n",
    "                print(\"Cannot save model!\")\n",
    "                final_model = None\n",
    "        \n",
    "        if final_model and os.path.exists(final_model):\n",
    "            model = YOLO(final_model)\n",
    "            print(f\"Loaded best model: {final_model}\")\n",
    "        else:\n",
    "            print(\"Using in-memory model\")\n",
    "        \n",
    "        self.plot_training_history()\n",
    "        self.evaluate_model(model, 'test')\n",
    "        self.evaluate_model(model, 'val')\n",
    "        self.visualize_predictions(model, split='test', n_samples=10)\n",
    "        self.visualize_predictions(model, split='val', n_samples=10)\n",
    "        self.visualize_tsne(model, 'test')\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRAINING COMPLETE!\")\n",
    "        print(f\"Output: {self.output_dir}\")\n",
    "        print(f\"Best model: {final_model if final_model else 'Not saved'}\")\n",
    "        print(f\"Time: {training_time/60:.1f} min\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "\n",
    "def main():\n",
    "    DATASET_ROOT = '/kaggle/input'\n",
    "    OUTPUT_DIR = '/kaggle/working/outputs'\n",
    "    EPOCHS = 200\n",
    "    BATCH_SIZE = 16\n",
    "    IMG_SIZE = 640\n",
    "    MAX_IMAGES = 2000  # None = full\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONFIG\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Root: {DATASET_ROOT}\")\n",
    "    print(f\"Output: {OUTPUT_DIR}\")\n",
    "    print(f\"Epochs: {EPOCHS} | Batch: {BATCH_SIZE} | Size: {IMG_SIZE}\")\n",
    "    print(f\"Max images: {MAX_IMAGES}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    if not os.path.exists(DATASET_ROOT):\n",
    "        print(f\"ERROR: {DATASET_ROOT} not found!\")\n",
    "        return\n",
    "    \n",
    "    trainer = RoadDamageTrainer(\n",
    "        dataset_root=DATASET_ROOT,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        img_size=IMG_SIZE,\n",
    "        max_images_per_dataset=MAX_IMAGES\n",
    "    )\n",
    "    trainer.run()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8570756,
     "sourceId": 13498785,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8577267,
     "sourceId": 13509230,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 279.688323,
   "end_time": "2025-11-09T09:05:04.275989",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-09T09:00:24.587666",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

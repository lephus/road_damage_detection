{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUV0tKk2l8JF",
        "outputId": "e8a1abfb-16e1-4768-fffe-a600d3bab533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting ZIP files:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:07,  1.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extracted: /content/RDD2022_China_Drone.zip â†’ /content/RDD2022_China_Drone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting ZIP files:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:03<00:05,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extracted: /content/RDD2022_China_MotorBike.zip â†’ /content/RDD2022_China_MotorBike\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting ZIP files:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:06<00:04,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extracted: /content/RDD2022_Czech.zip â†’ /content/RDD2022_Czech\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting ZIP files:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:13<00:04,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extracted: /content/RDD2022_India.zip â†’ /content/RDD2022_India\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting ZIP files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:28<00:00,  5.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extracted: /content/RDD2022_Japan.zip â†’ /content/RDD2022_Japan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Python code snippet to extract a .zip file in Google Colab\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# List of zip files\n",
        "zip_files = [\n",
        "    \"/content/RDD2022_China_Drone.zip\",\n",
        "    \"/content/RDD2022_China_MotorBike.zip\",\n",
        "    \"/content/RDD2022_Czech.zip\",\n",
        "    \"/content/RDD2022_India.zip\",\n",
        "    \"/content/RDD2022_Japan.zip\"\n",
        "]\n",
        "\n",
        "# Loop through and extract each zip\n",
        "for zip_path in tqdm(zip_files, desc=\"Extracting ZIP files\"):\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"âŒ File not found: {zip_path}\")\n",
        "        continue\n",
        "\n",
        "    extract_dir = os.path.splitext(zip_path)[0]  # remove .zip extension\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "\n",
        "    print(f\"âœ… Extracted: {zip_path} â†’ {extract_dir}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XÃ“A TOÃ€N Bá»˜ GÃ“I ÄÃƒ CÃ€I\n",
        "!pip freeze | xargs pip uninstall -y\n",
        "!pip install -U pip setuptools wheel --quiet\n",
        "!pip install numpy==1.26.4 pandas==2.2.2 matplotlib==3.9.2 seaborn==0.13.2 --quiet\n",
        "!pip install ultralytics==8.2.90 opencv-python-headless==4.10.0.84 tqdm pyyaml --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXkxy9XV-V_A",
        "outputId": "eae6ba6a-5635-4a75-da91-4c7e19b36ec0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: '@': Expected package name at the start of dependency specifier\n",
            "    @\n",
            "    ^\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires flax>=0.2.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jaxlib>=0.1.51, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Má»¥c má»›i"
      ],
      "metadata": {
        "id": "qVFhBtnM-qun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "\n",
        "print(\"âœ… Environment ready â€” YOLOv8 and dependencies loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maIRw83Z7Z2d",
        "outputId": "84568e8d-1275-4a13-a5de-7be9a7e1291b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Environment ready â€” YOLOv8 and dependencies loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pavement_damage_detection_yolo.py\n",
        "# Complete pipeline for pavement damage detection using YOLOv8\n",
        "# Runs end-to-end in Google Colab\n",
        "\n",
        "# import os\n",
        "# import xml.etree.ElementTree as ET\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
        "# from sklearn.manifold import TSNE\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from PIL import Image\n",
        "# import torch\n",
        "# from ultralytics import YOLO\n",
        "# import shutil\n",
        "# from pathlib import Path\n",
        "# import random\n",
        "\n",
        "# Define dataset paths\n",
        "dataset_paths = {\n",
        "    'India': {\n",
        "        'train_images': '/content/RDD2022_India/India/train/images',\n",
        "        'train_annotations': '/content/RDD2022_India/India/train/annotations',\n",
        "        'test_images': '/content/RDD2022_India/India/test/images'\n",
        "    },\n",
        "    'Czech': {\n",
        "        'train_images': '/content/RDD2022_Czech/Czech/train/images',\n",
        "        'train_annotations': '/content/RDD2022_Czech/Czech/train/annotations',\n",
        "        'test_images': '/content/RDD2022_Czech/Czech/test/images'\n",
        "    },\n",
        "    'China_MotorBike': {\n",
        "        'train_images': '/content/RDD2022_China_MotorBike/China_MotorBike/train/images',\n",
        "        'train_annotations': '/content/RDD2022_China_MotorBike/China_MotorBike/train/annotations',\n",
        "        'test_images': '/content/RDD2022_China_MotorBike/China_MotorBike/test/images'\n",
        "    },\n",
        "    'China_Drone': {\n",
        "        'train_images': '/content/RDD2022_China_Drone/China_Drone/train/images',\n",
        "        'train_annotations': '/content/RDD2022_China_Drone/China_Drone/train/annotations'\n",
        "    },\n",
        "    'Japan': {\n",
        "        'train_images': '/content/RDD2022_Japan/Japan/train/images',\n",
        "        'train_annotations': '/content/RDD2022_Japan/Japan/train/annotations',\n",
        "        'test_images': '/content/RDD2022_Japan/Japan/test/images'\n",
        "    },\n",
        "}\n",
        "\n",
        "# Valid class names (based on RDD2022 dataset)\n",
        "VALID_CLASSES = ['D00', 'D10', 'D20', 'D40', 'D43', 'D44']\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(VALID_CLASSES)}\n",
        "\n",
        "# Output directories\n",
        "OUTPUT_DIR = '/content/pavement_damage_yolo'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/train/images', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/train/labels', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/val/images', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/val/labels', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/test/images', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/test/labels', exist_ok=True)\n",
        "\n",
        "# Function to parse XML annotations and convert to YOLO format\n",
        "def parse_xml_to_yolo(xml_path, img_width, img_height):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "    labels = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        cls_name = obj.find('name').text\n",
        "        if cls_name not in VALID_CLASSES:\n",
        "            continue  # Skip invalid class names\n",
        "        cls_idx = class_to_idx[cls_name]\n",
        "\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = float(bbox.find('xmin').text)\n",
        "        ymin = float(bbox.find('ymin').text)\n",
        "        xmax = float(bbox.find('xmax').text)\n",
        "        ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "        # Skip invalid bounding boxes\n",
        "        if xmax <= xmin or ymax <= ymin:\n",
        "            continue\n",
        "\n",
        "        # Convert to YOLO format (center_x, center_y, width, height) normalized\n",
        "        center_x = (xmin + xmax) / 2 / img_width\n",
        "        center_y = (ymin + ymax) / 2 / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "\n",
        "        boxes.append([center_x, center_y, width, height])\n",
        "        labels.append(cls_idx)\n",
        "\n",
        "    return boxes, labels\n",
        "\n",
        "# Function to load and preprocess dataset\n",
        "def load_data():\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    for dataset_name, paths in dataset_paths.items():\n",
        "        img_dir = paths['train_images']\n",
        "        ann_dir = paths['train_annotations']\n",
        "\n",
        "        if not os.path.exists(img_dir) or not os.path.exists(ann_dir):\n",
        "            print(f\"Skipping {dataset_name}: Directory not found\")\n",
        "            continue\n",
        "\n",
        "        for img_file in os.listdir(img_dir):\n",
        "            if not img_file.endswith(('.jpg', '.png')):\n",
        "                continue\n",
        "            img_path = os.path.join(img_dir, img_file)\n",
        "            xml_path = os.path.join(ann_dir, 'xmls', f\"{img_file.split('.')[0]}.xml\")\n",
        "\n",
        "            if not os.path.exists(xml_path):\n",
        "                continue\n",
        "\n",
        "            # Read image to get dimensions\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            h, w = img.shape[:2]\n",
        "\n",
        "            # Parse annotations\n",
        "            try:\n",
        "                boxes, labels = parse_xml_to_yolo(xml_path, w, h)\n",
        "                if len(boxes) > 0 or len(labels) == 0:  # Include images with no valid boxes as background\n",
        "                    all_images.append(img_path)\n",
        "                    all_labels.append((boxes, labels, xml_path))\n",
        "                else:\n",
        "                    print(f\"Skipping {xml_path} due to no valid annotations\")\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {xml_path} due to error: {str(e)}\")\n",
        "\n",
        "    print(f\"Dataset initialized with {len(all_images)} valid image-annotation pairs.\")\n",
        "    return all_images, all_labels\n",
        "\n",
        "# Function to preprocess and save images/labels in YOLO format\n",
        "def preprocess_and_save(images, labels, split='train'):\n",
        "    img_out_dir = f'{OUTPUT_DIR}/{split}/images'\n",
        "    lbl_out_dir = f'{OUTPUT_DIR}/{split}/labels'\n",
        "\n",
        "    for img_path, (boxes, lbls, xml_path) in zip(images, labels):\n",
        "        # Copy and preprocess image\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (640, 640))  # Resize to 640x640 for YOLO\n",
        "        img_name = os.path.basename(img_path)\n",
        "        cv2.imwrite(os.path.join(img_out_dir, img_name), img)\n",
        "\n",
        "        # Save YOLO annotations\n",
        "        lbl_path = os.path.join(lbl_out_dir, f\"{img_name.split('.')[0]}.txt\")\n",
        "        with open(lbl_path, 'w') as f:\n",
        "            for box, lbl in zip(boxes, lbls):\n",
        "                f.write(f\"{lbl} {' '.join(map(str, box))}\\n\")\n",
        "\n",
        "# Function to split dataset\n",
        "def split_dataset(images, labels):\n",
        "    train_imgs, test_imgs, train_lbls, test_lbls = train_test_split(\n",
        "        images, labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "    train_imgs, val_imgs, train_lbls, val_lbls = train_test_split(\n",
        "        train_imgs, train_lbls, test_size=0.25, random_state=42  # 0.25 * 0.8 = 0.2\n",
        "    )\n",
        "\n",
        "    preprocess_and_save(train_imgs, train_lbls, 'train')\n",
        "    preprocess_and_save(val_imgs, val_lbls, 'val')\n",
        "    preprocess_and_save(test_imgs, test_lbls, 'test')\n",
        "\n",
        "    return len(train_imgs), len(val_imgs), len(test_imgs)\n",
        "\n",
        "# Function to create YOLO config file\n",
        "def create_yolo_config():\n",
        "    config = f\"\"\"\n",
        "path: {OUTPUT_DIR}\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "nc: {len(VALID_CLASSES)}\n",
        "names: {VALID_CLASSES}\n",
        "\"\"\"\n",
        "    with open(f'{OUTPUT_DIR}/data.yaml', 'w') as f:\n",
        "        f.write(config)\n",
        "\n",
        "# Function to build and train YOLO model\n",
        "def train_model():\n",
        "    model = YOLO('yolov8n.pt')  # Load pretrained YOLOv8n (nano) for speed\n",
        "    # results = model.train(\n",
        "    #     data=f'{OUTPUT_DIR}/data.yaml',\n",
        "    #     epochs=50,  # Reduced for demo speed\n",
        "    #     imgsz=640,\n",
        "    #     batch=16,\n",
        "    #     device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    #     name='pavement_damage'\n",
        "    # )\n",
        "    results = model.train(\n",
        "        data=f'{OUTPUT_DIR}/data.yaml',\n",
        "        epochs=50,\n",
        "        imgsz=640,\n",
        "        batch=32,\n",
        "        device=0 if torch.cuda.is_available() else 'cpu',\n",
        "        augment=True,\n",
        "        lr0=0.001,\n",
        "        cos_lr=True,\n",
        "        patience=10,\n",
        "        amp=True,  # Báº­t mixed precision\n",
        "        name='pavement_damage_optimized'\n",
        "    )\n",
        "    return model, results\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, test_images):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    y_scores = []\n",
        "\n",
        "    for img_path in test_images:\n",
        "        img = cv2.imread(img_path)\n",
        "        results = model.predict(img, conf=0.5)\n",
        "\n",
        "        # Get ground truth\n",
        "        xml_path = img_path.replace('images', 'annotations').replace('.jpg', '.xml').replace('.png', '.xml')\n",
        "        boxes, labels = parse_xml_to_yolo(xml_path, img.shape[1], img.shape[0])\n",
        "        y_true.extend(labels if labels else [len(VALID_CLASSES)])  # Background class\n",
        "\n",
        "        # Get predictions\n",
        "        pred_labels = []\n",
        "        for box in results[0].boxes:\n",
        "            pred_labels.append(int(box.cls))\n",
        "            y_scores.append(float(box.conf))\n",
        "        y_pred.extend(pred_labels if pred_labels else [len(VALID_CLASSES)])\n",
        "\n",
        "    # Pad lists to equal length\n",
        "    max_len = max(len(y_true), len(y_pred))\n",
        "    y_true.extend([len(VALID_CLASSES)] * (max_len - len(y_true)))\n",
        "    y_pred.extend([len(VALID_CLASSES)] * (max_len - len(y_pred)))\n",
        "    y_scores.extend([0.0] * (max_len - len(y_scores)))\n",
        "\n",
        "    # Compute metrics\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "    # ROC Curve and AUC\n",
        "    y_true_bin = [1 if x != len(VALID_CLASSES) else 0 for x in y_true]\n",
        "    y_scores = np.array(y_scores)\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin, y_scores, pos_label=1)\n",
        "    auc_score = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{OUTPUT_DIR}/roc_curve.png')\n",
        "    plt.show()\n",
        "\n",
        "    return precision, recall, f1, auc_score\n",
        "\n",
        "# Function to visualize training curves\n",
        "def visualize_training_curves(results):\n",
        "    metrics = results.results_dict\n",
        "    epochs = range(1, len(metrics['metrics/loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, metrics['metrics/loss'], label='Training Loss')\n",
        "    plt.plot(epochs, metrics['metrics/val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, metrics['metrics/mAP50'], label='mAP@0.5')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('mAP@0.5')\n",
        "    plt.title('Training mAP@0.5')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(f'{OUTPUT_DIR}/training_curves.png')\n",
        "    plt.show()\n",
        "\n",
        "# Function to visualize sample predictions\n",
        "def visualize_predictions(model, test_images, n_samples=5):\n",
        "    samples = random.sample(test_images, min(n_samples, len(test_images)))\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(samples):\n",
        "        img = cv2.imread(img_path)\n",
        "        results = model.predict(img, conf=0.5)\n",
        "\n",
        "        # Draw ground truth\n",
        "        xml_path = img_path.replace('images', 'annotations').replace('.jpg', '.xml').replace('.png', '.xml')\n",
        "        boxes, labels = parse_xml_to_yolo(xml_path, img.shape[1], img.shape[0])\n",
        "        for box, lbl in zip(boxes, labels):\n",
        "            x, y, w, h = box\n",
        "            x1 = int((x - w/2) * img.shape[1])\n",
        "            y1 = int((y - h/2) * img.shape[0])\n",
        "            x2 = int((x + w/2) * img.shape[1])\n",
        "            y2 = int((y + h/2) * img.shape[0])\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(img, VALID_CLASSES[lbl], (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        # Draw predictions\n",
        "        for box in results[0].boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls)\n",
        "            conf = float(box.conf)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "            cv2.putText(img, f\"{VALID_CLASSES[cls]} {conf:.2f}\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "        plt.subplot(1, n_samples, i+1)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig(f'{OUTPUT_DIR}/sample_predictions.png')\n",
        "    plt.show()\n",
        "\n",
        "# Function to compute t-SNE visualization\n",
        "def visualize_tsne(model, test_images):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for img_path in test_images[:100]:  # Limit for speed\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (640, 640))\n",
        "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float().unsqueeze(0).cuda() / 255.0\n",
        "        feat = model.model.forward(img_tensor, augment=False)[1][-1].cpu().detach().numpy().flatten()\n",
        "        features.append(feat)\n",
        "\n",
        "        xml_path = img_path.replace('images', 'annotations').replace('.jpg', '.xml').replace('.png', '.xml')\n",
        "        _, lbls = parse_xml_to_yolo(xml_path, img.shape[1], img.shape[0])\n",
        "        labels.append(lbls[0] if lbls else len(VALID_CLASSES))\n",
        "\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    embeddings = tsne.fit_transform(np.array(features))\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap='viridis')\n",
        "    plt.legend(handles=scatter.legend_elements()[0], labels=VALID_CLASSES + ['Background'])\n",
        "    plt.title('t-SNE Visualization of Feature Embeddings')\n",
        "    plt.savefig(f'{OUTPUT_DIR}/tsne.png')\n",
        "    plt.show()\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    print(\"Loading data...\")\n",
        "    images, labels = load_data()\n",
        "\n",
        "    print(\"Splitting dataset...\")\n",
        "    n_train, n_val, n_test = split_dataset(images, labels)\n",
        "    print(f\"Train: {n_train}, Validation: {n_val}, Test: {n_test}\")\n",
        "\n",
        "    print(\"Creating YOLO config...\")\n",
        "    create_yolo_config()\n",
        "\n",
        "    print(\"Training model...\")\n",
        "    model, results = train_model()\n",
        "\n",
        "    print(\"Evaluating model...\")\n",
        "    test_images = [os.path.join(f'{OUTPUT_DIR}/test/images', f) for f in os.listdir(f'{OUTPUT_DIR}/test/images')]\n",
        "    precision, recall, f1, auc_score = evaluate_model(model, test_images)\n",
        "\n",
        "    print(\"Visualizing training curves...\")\n",
        "    visualize_training_curves(results)\n",
        "\n",
        "    print(\"Visualizing sample predictions...\")\n",
        "    visualize_predictions(model, test_images)\n",
        "\n",
        "    print(\"Visualizing t-SNE...\")\n",
        "    visualize_tsne(model, test_images)\n",
        "\n",
        "    print(\"Saving model...\")\n",
        "    model.save(f'{OUTPUT_DIR}/pavement_damage_yolo.pt')\n",
        "\n",
        "    print(\"Saving metrics...\")\n",
        "    with open(f'{OUTPUT_DIR}/metrics.txt', 'w') as f:\n",
        "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
        "        f.write(f\"Recall: {recall:.4f}\\n\")\n",
        "        f.write(f\"F1-Score: {f1:.4f}\\n\")\n",
        "        f.write(f\"AUC: {auc_score:.4f}\\n\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG6XNuMKFQ-I",
        "outputId": "af2e8c51-b528-4dcb-fb5c-91fede10da4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Dataset initialized with 25419 valid image-annotation pairs.\n",
            "Splitting dataset...\n",
            "Train: 15251, Validation: 5084, Test: 5084\n",
            "Creating YOLO config...\n",
            "Training model...\n",
            "New https://pypi.org/project/ultralytics/8.3.221 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.90 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/pavement_damage_yolo/data.yaml, epochs=50, time=None, patience=10, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=pavement_damage_optimized2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/pavement_damage_optimized2\n",
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/pavement_damage_optimized2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/pavement_damage_yolo/train/labels.cache... 15251 images, 4467 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15251/15251 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/data/augment.py:1837: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0),\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/pavement_damage_yolo/val/labels.cache... 5084 images, 1493 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5084/5084 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/pavement_damage_optimized2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/pavement_damage_optimized2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      4.48G      2.006      4.102      1.861         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [05:00<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  18%|â–ˆâ–Š        | 14/80 [00:09<00:43,  1.53it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 5. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:50<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.258      0.228      0.153     0.0582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      4.56G      1.948      3.115      1.771         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:45<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  19%|â–ˆâ–‰        | 15/80 [00:09<00:39,  1.65it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 5. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.252      0.197      0.134     0.0632\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      4.49G       2.02      2.877      1.832         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:43<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  11%|â–ˆâ–        | 9/80 [00:05<00:41,  1.72it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 3 that is less than the current step 5. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.163      0.278       0.12     0.0523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      4.47G      2.075      2.822      1.899         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:42<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   5%|â–Œ         | 4/80 [00:02<00:53,  1.43it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 4 that is less than the current step 5. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:47<00:00,  1.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.279      0.246      0.186     0.0765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50       4.5G      2.015      2.661       1.86         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:34<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.263      0.241      0.174     0.0773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      4.49G      1.966      2.559      1.819         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:25<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:43<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682       0.37      0.295      0.259      0.122\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      4.49G      1.918      2.484      1.787         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:31<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.429       0.32       0.31      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      4.42G      1.884      2.411      1.757         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:33<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.389      0.348      0.315      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      4.48G      1.877       2.37       1.75         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:34<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.422      0.387      0.372      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      4.45G      1.848      2.328      1.741         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:38<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.417      0.376      0.341       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50       4.5G      1.835      2.299      1.718         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:47<00:00,  1.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.489      0.399      0.402      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      4.45G      1.819      2.252      1.697         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.491      0.392      0.404        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      4.45G      1.802      2.219      1.683         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:32<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.503      0.425      0.432      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      4.42G      1.785      2.202       1.68         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:36<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.495      0.446      0.443      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      4.45G      1.776       2.17       1.67         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:34<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.501      0.439      0.441      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      4.45G      1.754      2.139      1.662         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.501      0.422      0.429      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      4.45G       1.76      2.127      1.654         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:41<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.541      0.459      0.469      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      4.45G      1.735      2.093       1.64         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:47<00:00,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.527       0.46      0.479      0.243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      4.45G      1.739      2.085      1.637         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:33<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.534      0.468      0.472      0.247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      4.51G      1.722      2.053      1.628         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:32<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:43<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.556      0.472      0.489      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      4.48G      1.707      2.034      1.618         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:25<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.537       0.48      0.496       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50       4.5G      1.707      2.015      1.612         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:28<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.566      0.488      0.506      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      4.51G      1.687      1.973      1.595         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:27<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.571      0.493      0.522       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      4.49G      1.683      1.958      1.592         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:22<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:43<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.586      0.502      0.527      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      4.44G      1.675      1.933      1.582         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:29<00:00,  1.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:43<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.561      0.516      0.534      0.291\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      4.49G      1.665      1.929      1.579         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:30<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.579      0.513       0.54      0.293\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      4.44G      1.658      1.903      1.565         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:33<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.578      0.514      0.538      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      4.45G      1.648      1.893      1.559         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:38<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.607      0.522      0.557      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      4.49G      1.635      1.862      1.547         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:36<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682        0.6      0.533      0.561      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      4.45G      1.626      1.852      1.548         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:37<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.606      0.525      0.566      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      4.44G      1.619      1.825      1.536         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:32<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.611       0.53      0.571      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50       4.5G      1.604      1.806       1.53         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.606      0.538      0.573      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      4.43G      1.599      1.794      1.523         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.607      0.536      0.571      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      4.48G      1.589      1.771      1.519         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682       0.62      0.543       0.58       0.32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      4.45G      1.587      1.764      1.518         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:36<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.628      0.547       0.59      0.324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      4.48G      1.578      1.743      1.503         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.626      0.542      0.587      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      4.48G      1.565       1.72      1.497         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:30<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.615      0.556      0.591      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      4.48G      1.555      1.688      1.489         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:35<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:45<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682       0.62      0.557      0.594      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      4.45G      1.552      1.687      1.486         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:29<00:00,  1.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.635      0.546      0.592      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      4.45G      1.538      1.676       1.48         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:39<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:46<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.624      0.554      0.594      0.331\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/data/augment.py:1837: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      4.44G      1.554      1.608      1.532         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:21<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:43<00:00,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.628      0.554      0.598      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      4.44G      1.546      1.569      1.528         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:14<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:43<00:00,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.642      0.556      0.602      0.337\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      4.43G      1.531      1.551      1.522         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 477/477 [04:13<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:44<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       5084       7682      0.653      0.552      0.604      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      4.44G      1.523      1.532      1.512         83        640:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 207/477 [01:50<03:07,  1.44it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Replace with your folder path\n",
        "folder_path = \"runs/detect/pavement_damage3\"\n",
        "zip_path = \"/content/outputs.zip\"\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive(\"/content/outputs\", 'zip', folder_path)\n",
        "\n",
        "# Download\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ClFxW-ATqOce",
        "outputId": "e8acf1a8-6490-4f54-86e8-58f74bf22ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1e89236a-f574-4e28-bcba-3f593d866474\", \"outputs.zip\", 18420403)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
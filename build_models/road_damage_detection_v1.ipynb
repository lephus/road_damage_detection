{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgbRsJKasxCg"
      },
      "outputs": [],
      "source": [
        "# Python code snippet to extract a .zip file in Google Colab\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# List of zip files\n",
        "zip_files = [\n",
        "    \"/RDD2022_China_Drone.zip\",\n",
        "    \"/RDD2022_China_MotorBike.zip\",\n",
        "    \"/RDD2022_Czech.zip\",\n",
        "    \"/RDD2022_India.zip\",\n",
        "]\n",
        "\n",
        "# Loop through and extract each zip\n",
        "for zip_path in tqdm(zip_files, desc=\"Extracting ZIP files\"):\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"❌ File not found: {zip_path}\")\n",
        "        continue\n",
        "\n",
        "    extract_dir = os.path.splitext(zip_path)[0]  # remove .zip extension\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "\n",
        "    print(f\"✅ Extracted: {zip_path} → {extract_dir}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Clean and install compatible versions ---\n",
        "!pip install jedi>=0.16\n",
        "!pip install -U pip setuptools wheel --quiet\n",
        "!pip uninstall -y numpy jax jaxlib pytensor thinc --quiet\n",
        "\n",
        "\n",
        "# Reinstall compatible dependencies\n",
        "!pip install numpy>=2.0\n",
        "!pip install ultralytics==8.2.90 opencv-python-headless==4.10.0.84 seaborn tqdm pyyaml --quiet\n"
      ],
      "metadata": {
        "id": "u8ZEOEjfs0rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import yaml\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# YOLOv8\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"✅ Environment ready — YOLOv8 and dependencies loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "FAKgK2RYs2RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define dataset paths\n",
        "dataset_paths = {\n",
        "    'India': {\n",
        "        'train_images': '/RDD2022_India/India/train/images',\n",
        "        'train_annotations': '/RDD2022_India/India/train/annotations',\n",
        "        'test_images': '/RDD2022_India/India/test/images'\n",
        "    },\n",
        "    'Czech': {\n",
        "        'train_images': '/RDD2022_Czech/train/images',\n",
        "        'train_annotations': '/RDD2022_Czech/train/annotations',\n",
        "        'test_images': '/RDD2022_Czech/test/images'\n",
        "    },\n",
        "    'China_MotorBike': {\n",
        "        'train_images': '/RDD2022_China_MotorBike/China_MotorBike/train/images',\n",
        "        'train_annotations': '/RDD2022_China_MotorBike/China_MotorBike/train/annotations',\n",
        "        'test_images': '/RDD2022_China_MotorBike/China_MotorBike/test/images'\n",
        "    },\n",
        "    'China_Drone': {\n",
        "        'train_images': '/RDD2022_China_Drone/China_Drone/train/images',\n",
        "        'train_annotations': '/RDD2022_China_Drone/China_Drone/train/annotations'\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "0NBI9lPWs5t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Valid class names (based on RDD2022 dataset)\n",
        "VALID_CLASSES = ['D00', 'D10', 'D20', 'D40', 'D43', 'D44']\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(VALID_CLASSES)}\n",
        "\n",
        "# Output directories\n",
        "OUTPUT_DIR = '/content/pavement_damage_yolo'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/train/images', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/train/labels', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/val/images', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/val/labels', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/test/images', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/test/labels', exist_ok=True)\n"
      ],
      "metadata": {
        "id": "eyoMFm3Ds8AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to parse XML annotations and convert to YOLO format\n",
        "def parse_xml_to_yolo(xml_path, img_width, img_height):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    boxes = []\n",
        "    labels = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        cls_name = obj.find('name').text\n",
        "        if cls_name not in VALID_CLASSES:\n",
        "            continue  # Skip invalid class names\n",
        "        cls_idx = class_to_idx[cls_name]\n",
        "\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = float(bbox.find('xmin').text)\n",
        "        ymin = float(bbox.find('ymin').text)\n",
        "        xmax = float(bbox.find('xmax').text)\n",
        "        ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "        # Skip invalid bounding boxes\n",
        "        if xmax <= xmin or ymax <= ymin:\n",
        "            continue\n",
        "\n",
        "        # Convert to YOLO format (center_x, center_y, width, height) normalized\n",
        "        center_x = (xmin + xmax) / 2 / img_width\n",
        "        center_y = (ymin + ymax) / 2 / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "\n",
        "        boxes.append([center_x, center_y, width, height])\n",
        "        labels.append(cls_idx)\n",
        "\n",
        "    return boxes, labels\n"
      ],
      "metadata": {
        "id": "tmGPGYV1s9Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to load and preprocess dataset\n",
        "def load_data():\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    for dataset_name, paths in dataset_paths.items():\n",
        "        img_dir = paths['train_images']\n",
        "        ann_dir = paths['train_annotations']\n",
        "\n",
        "        if not os.path.exists(img_dir) or not os.path.exists(ann_dir):\n",
        "            print(f\"Skipping {dataset_name}: Directory not found\")\n",
        "            continue\n",
        "\n",
        "        for img_file in os.listdir(img_dir):\n",
        "            if not img_file.endswith(('.jpg', '.png')):\n",
        "                continue\n",
        "            img_path = os.path.join(img_dir, img_file)\n",
        "            xml_path = os.path.join(ann_dir, 'xmls', f\"{img_file.split('.')[0]}.xml\")\n",
        "\n",
        "            if not os.path.exists(xml_path):\n",
        "                continue\n",
        "\n",
        "            # Read image to get dimensions\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            h, w = img.shape[:2]\n",
        "\n",
        "            # Parse annotations\n",
        "            try:\n",
        "                boxes, labels = parse_xml_to_yolo(xml_path, w, h)\n",
        "                if len(boxes) > 0 or len(labels) == 0:  # Include images with no valid boxes as background\n",
        "                    all_images.append(img_path)\n",
        "                    all_labels.append((boxes, labels, xml_path))\n",
        "                else:\n",
        "                    print(f\"Skipping {xml_path} due to no valid annotations\")\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {xml_path} due to error: {str(e)}\")\n",
        "\n",
        "    print(f\"Dataset initialized with {len(all_images)} valid image-annotation pairs.\")\n",
        "    return all_images, all_labels\n"
      ],
      "metadata": {
        "id": "OpvbJkrcs_BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to preprocess and save images/labels in YOLO format\n",
        "def preprocess_and_save(images, labels, split='train'):\n",
        "    img_out_dir = f'{OUTPUT_DIR}/{split}/images'\n",
        "    lbl_out_dir = f'{OUTPUT_DIR}/{split}/labels'\n",
        "\n",
        "    for img_path, (boxes, lbls, xml_path) in zip(images, labels):\n",
        "        # Copy and preprocess image\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (640, 640))  # Resize to 640x640 for YOLO\n",
        "        img_name = os.path.basename(img_path)\n",
        "        cv2.imwrite(os.path.join(img_out_dir, img_name), img)\n",
        "\n",
        "        # Save YOLO annotations\n",
        "        lbl_path = os.path.join(lbl_out_dir, f\"{img_name.split('.')[0]}.txt\")\n",
        "        with open(lbl_path, 'w') as f:\n",
        "            for box, lbl in zip(boxes, lbls):\n",
        "                f.write(f\"{lbl} {' '.join(map(str, box))}\\n\")\n",
        "\n",
        "# Function to split dataset\n",
        "def split_dataset(images, labels):\n",
        "    train_imgs, test_imgs, train_lbls, test_lbls = train_test_split(\n",
        "        images, labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "    train_imgs, val_imgs, train_lbls, val_lbls = train_test_split(\n",
        "        train_imgs, train_lbls, test_size=0.25, random_state=42  # 0.25 * 0.8 = 0.2\n",
        "    )\n",
        "\n",
        "    preprocess_and_save(train_imgs, train_lbls, 'train')\n",
        "    preprocess_and_save(val_imgs, val_lbls, 'val')\n",
        "    preprocess_and_save(test_imgs, test_lbls, 'test')\n",
        "\n",
        "    return len(train_imgs), len(val_imgs), len(test_imgs)\n",
        "\n",
        "# Function to create YOLO config file\n",
        "def create_yolo_config():\n",
        "    config = f\"\"\"\n",
        "path: {OUTPUT_DIR}\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "nc: {len(VALID_CLASSES)}\n",
        "names: {VALID_CLASSES}\n",
        "\"\"\"\n",
        "    with open(f'{OUTPUT_DIR}/data.yaml', 'w') as f:\n",
        "        f.write(config)\n",
        "\n",
        "# Function to build and train YOLO model\n",
        "def train_model():\n",
        "    model = YOLO('yolov8n.pt')  # Load pretrained YOLOv8n (nano) for speed\n",
        "    results = model.train(\n",
        "        data=f'{OUTPUT_DIR}/data.yaml',\n",
        "        epochs=50,  # Reduced for demo speed\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        device=0 if torch.cuda.is_available() else 'cpu',\n",
        "        name='pavement_damage'\n",
        "    )\n",
        "    return model, results\n"
      ],
      "metadata": {
        "id": "4vZ2juOvtCtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, test_images):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    y_scores = []\n",
        "\n",
        "    for img_path in test_images:\n",
        "        img = cv2.imread(img_path)\n",
        "        results = model.predict(img, conf=0.5)\n",
        "\n",
        "        # Get ground truth\n",
        "        xml_path = img_path.replace('images', 'annotations').replace('.jpg', '.xml').replace('.png', '.xml')\n",
        "        boxes, labels = parse_xml_to_yolo(xml_path, img.shape[1], img.shape[0])\n",
        "        y_true.extend(labels if labels else [len(VALID_CLASSES)])  # Background class\n",
        "\n",
        "        # Get predictions\n",
        "        pred_labels = []\n",
        "        for box in results[0].boxes:\n",
        "            pred_labels.append(int(box.cls))\n",
        "            y_scores.append(float(box.conf))\n",
        "        y_pred.extend(pred_labels if pred_labels else [len(VALID_CLASSES)])\n",
        "\n",
        "    # Pad lists to equal length\n",
        "    max_len = max(len(y_true), len(y_pred))\n",
        "    y_true.extend([len(VALID_CLASSES)] * (max_len - len(y_true)))\n",
        "    y_pred.extend([len(VALID_CLASSES)] * (max_len - len(y_pred)))\n",
        "    y_scores.extend([0.0] * (max_len - len(y_scores)))\n",
        "\n",
        "    # Compute metrics\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "    # ROC Curve and AUC\n",
        "    y_true_bin = [1 if x != len(VALID_CLASSES) else 0 for x in y_true]\n",
        "    y_scores = np.array(y_scores)\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin, y_scores, pos_label=1)\n",
        "    auc_score = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{OUTPUT_DIR}/roc_curve.png')\n",
        "    plt.show()\n",
        "\n",
        "    return precision, recall, f1, auc_score\n"
      ],
      "metadata": {
        "id": "bBluCWoBtFS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to visualize training curves\n",
        "def visualize_training_curves(results):\n",
        "    metrics = results.results_dict\n",
        "    epochs = range(1, len(metrics['metrics/loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, metrics['metrics/loss'], label='Training Loss')\n",
        "    plt.plot(epochs, metrics['metrics/val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, metrics['metrics/mAP50'], label='mAP@0.5')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('mAP@0.5')\n",
        "    plt.title('Training mAP@0.5')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(f'{OUTPUT_DIR}/training_curves.png')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "8nyNQHtNtHfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to visualize sample predictions\n",
        "def visualize_predictions(model, test_images, n_samples=5):\n",
        "    samples = random.sample(test_images, min(n_samples, len(test_images)))\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, img_path in enumerate(samples):\n",
        "        img = cv2.imread(img_path)\n",
        "        results = model.predict(img, conf=0.5)\n",
        "\n",
        "        # Draw ground truth\n",
        "        xml_path = img_path.replace('images', 'annotations').replace('.jpg', '.xml').replace('.png', '.xml')\n",
        "        boxes, labels = parse_xml_to_yolo(xml_path, img.shape[1], img.shape[0])\n",
        "        for box, lbl in zip(boxes, labels):\n",
        "            x, y, w, h = box\n",
        "            x1 = int((x - w/2) * img.shape[1])\n",
        "            y1 = int((y - h/2) * img.shape[0])\n",
        "            x2 = int((x + w/2) * img.shape[1])\n",
        "            y2 = int((y + h/2) * img.shape[0])\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(img, VALID_CLASSES[lbl], (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "        # Draw predictions\n",
        "        for box in results[0].boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls)\n",
        "            conf = float(box.conf)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "            cv2.putText(img, f\"{VALID_CLASSES[cls]} {conf:.2f}\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "        plt.subplot(1, n_samples, i+1)\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig(f'{OUTPUT_DIR}/sample_predictions.png')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "DRR8fjgAtJLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to compute t-SNE visualization\n",
        "def visualize_tsne(model, test_images):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for img_path in test_images[:100]:  # Limit for speed\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (640, 640))\n",
        "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float().unsqueeze(0).cuda() / 255.0\n",
        "        feat = model.model.forward(img_tensor, augment=False)[1][-1].cpu().detach().numpy().flatten()\n",
        "        features.append(feat)\n",
        "\n",
        "        xml_path = img_path.replace('images', 'annotations').replace('.jpg', '.xml').replace('.png', '.xml')\n",
        "        _, lbls = parse_xml_to_yolo(xml_path, img.shape[1], img.shape[0])\n",
        "        labels.append(lbls[0] if lbls else len(VALID_CLASSES))\n",
        "\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    embeddings = tsne.fit_transform(np.array(features))\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    scatter = plt.scatter(embeddings[:, 0], embeddings[:, 1], c=labels, cmap='viridis')\n",
        "    plt.legend(handles=scatter.legend_elements()[0], labels=VALID_CLASSES + ['Background'])\n",
        "    plt.title('t-SNE Visualization of Feature Embeddings')\n",
        "    plt.savefig(f'{OUTPUT_DIR}/tsne.png')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iWmU74-StLPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading data...\")\n",
        "images, labels = load_data()\n",
        "\n",
        "print(\"Splitting dataset...\")\n",
        "n_train, n_val, n_test = split_dataset(images, labels)\n",
        "print(f\"Train: {n_train}, Validation: {n_val}, Test: {n_test}\")\n",
        "\n",
        "print(\"Creating YOLO config...\")\n",
        "create_yolo_config()\n",
        "\n",
        "print(\"Training model...\")\n",
        "model, results = train_model()\n",
        "\n",
        "print(\"Evaluating model...\")\n",
        "test_images = [os.path.join(f'{OUTPUT_DIR}/test/images', f) for f in os.listdir(f'{OUTPUT_DIR}/test/images')]\n",
        "precision, recall, f1, auc_score = evaluate_model(model, test_images)\n",
        "\n",
        "print(\"Visualizing training curves...\")\n",
        "visualize_training_curves(results)\n",
        "\n",
        "print(\"Visualizing sample predictions...\")\n",
        "visualize_predictions(model, test_images)\n",
        "\n",
        "print(\"Visualizing t-SNE...\")\n",
        "visualize_tsne(model, test_images)\n",
        "\n",
        "print(\"Saving model...\")\n",
        "model.save(f'{OUTPUT_DIR}/pavement_damage_yolo.pt')\n",
        "\n",
        "print(\"Saving metrics...\")\n",
        "with open(f'{OUTPUT_DIR}/metrics.txt', 'w') as f:\n",
        "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
        "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
        "    f.write(f\"F1-Score: {f1:.4f}\\n\")\n",
        "    f.write(f\"AUC: {auc_score:.4f}\\n\")"
      ],
      "metadata": {
        "id": "WwL6o_S7tOaB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}